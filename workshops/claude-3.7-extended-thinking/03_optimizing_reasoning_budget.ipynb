{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74eee332-b693-4a4b-8265-be6fdaa090f9",
   "metadata": {},
   "source": [
    "# Optimizing Reasoning Budget Allocation\n",
    "\n",
    "In this notebook, we'll explore how to optimize Claude 3.7 Sonnet's reasoning budget allocation to balance quality, cost, and performance. Building on what we learned in the previous two lessons, we'll develop practical strategies to:\n",
    "\n",
    "1. **Dynamically allocate reasoning budgets** based on task requirements\n",
    "2. **Visualize the tradeoffs** between budget size, response quality, and cost  \n",
    "3. **Create reusable patterns** for different kinds of applications\n",
    "\n",
    "By the end of this lesson, you'll have practical approaches for determining the right amount of \"thinking power\" to allocate for different tasks.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This notebook builds on concepts covered in Lessons 1 and 2:\n",
    "- Understanding of Claude 3.7's extended thinking capability\n",
    "- Familiarity with the Bedrock API for invoking Claude\n",
    "- Task complexity classification framework\n",
    "\n",
    "Let's begin by setting up our environment and importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff68a4-7fab-4769-b536-b6c4a954af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "# Import our utility functions from previous lessons\n",
    "import claude_utils\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# Configure pandas display options\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eeac36-8262-4c8a-bbfd-cf5b3f9579b3",
   "metadata": {},
   "source": [
    "#### Initialize Bedrock Clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff3c2b-3660-4a41-91d8-0e4dde3c851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Bedrock clients using our utility module\n",
    "REGION = 'us-west-2'  # Change to your preferred region\n",
    "bedrock, bedrock_runtime = claude_utils.create_bedrock_clients(REGION)\n",
    "\n",
    "# Claude 3.7 Sonnet model ID\n",
    "CLAUDE_37_SONNET_MODEL_ID = 'us.anthropic.claude-3-7-sonnet-20250219-v1:0'\n",
    "\n",
    "# Verify model availability\n",
    "claude_utils.verify_model_availability(bedrock, CLAUDE_37_SONNET_MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d22909-1f0f-4623-95a4-6aa78eb835e0",
   "metadata": {},
   "source": [
    "## Recap: The Reasoning Budget Concept\n",
    "\n",
    "Before diving into optimization strategies, let's quickly recap what we've learned about Claude's reasoning budget:\n",
    "\n",
    "- The **reasoning budget** is the number of tokens allocated for Claude's extended thinking process\n",
    "- Minimum reasoning budget is **1,024 tokens**\n",
    "- Larger budgets allow for more thorough reasoning on complex problems\n",
    "- Extended thinking incurs costs as part of the output tokens ($15 per million tokens)\n",
    "\n",
    "Think of the reasoning budget like allocating CPU time to a computational task - more complex tasks benefit from larger allocations, but there are diminishing returns beyond a certain point.\n",
    "\n",
    "In this lesson, we'll focus on finding the \"sweet spot\" for different types of tasks - optimizing for both performance and cost-effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9348313b-15b9-4162-a592-bba349cd8637",
   "metadata": {},
   "source": [
    "## Understanding the Tradeoffs of Budget Allocation\n",
    "\n",
    "Before we implement a dynamic budget allocation system, let's understand the key tradeoffs involved:\n",
    "\n",
    "1. **Budget Size vs. Response Quality**: Larger budgets generally lead to more thorough reasoning and potentially better responses, but with diminishing returns\n",
    "   \n",
    "2. **Budget Size vs. Response Time**: Larger budgets increase processing time as Claude spends more time thinking\n",
    "   \n",
    "3. **Budget Size vs. Cost**: Larger budgets increase token usage and therefore cost\n",
    "\n",
    "These tradeoffs create an optimization challenge - finding the right budget that balances quality, speed, and cost for a specific task.\n",
    "\n",
    "Let's explore these tradeoffs by testing a range of reasoning budgets on a moderately complex problem and measuring the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6834e01b-68ee-4737-8273-d5dc18994672",
   "metadata": {},
   "source": [
    "#### Testing Different Budget Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d486de0-ec35-4bf4-b71e-a2b415688a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reasoning_budgets(prompt, budget_sizes=[1024, 2048, 4096, 8192, 16384], max_tokens=2000):\n",
    "    \"\"\"\n",
    "    Test different reasoning budget sizes on the same prompt and collect performance metrics\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The prompt to test\n",
    "        budget_sizes (list): List of reasoning budget sizes to test\n",
    "        max_tokens (int): Maximum tokens for responses\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Performance metrics for each budget size\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"Testing prompt: {prompt[:100]}...\" if len(prompt) > 100 else f\"Testing prompt: {prompt}\")\n",
    "    print(f\"Testing {len(budget_sizes)} different reasoning budget sizes...\\n\")\n",
    "    \n",
    "    for budget in budget_sizes:\n",
    "        print(f\"Testing reasoning budget: {budget} tokens\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        response = claude_utils.invoke_claude(\n",
    "            bedrock_runtime,\n",
    "            prompt, \n",
    "            CLAUDE_37_SONNET_MODEL_ID, \n",
    "            enable_reasoning=True,\n",
    "            reasoning_budget=budget,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # Extract metrics\n",
    "        input_tokens = response.get('usage', {}).get('inputTokens', 0)\n",
    "        output_tokens = response.get('usage', {}).get('outputTokens', 0)\n",
    "        total_tokens = response.get('usage', {}).get('totalTokens', 0)\n",
    "        \n",
    "        # Calculate costs (approximate)\n",
    "        input_cost = input_tokens * 0.000003  # $3 per million tokens\n",
    "        output_cost = output_tokens * 0.000015  # $5 per million tokens\n",
    "        total_cost = input_cost + output_cost\n",
    "        \n",
    "        # Calculate efficiency (tokens per second)\n",
    "        efficiency = total_tokens / elapsed_time if elapsed_time > 0 else 0\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'budget': budget,\n",
    "            'elapsed_time': elapsed_time,\n",
    "            'input_tokens': input_tokens,\n",
    "            'output_tokens': output_tokens,\n",
    "            'total_tokens': total_tokens,\n",
    "            'input_cost': input_cost,\n",
    "            'output_cost': output_cost,\n",
    "            'total_cost': total_cost,\n",
    "            'efficiency': efficiency,\n",
    "            'response': claude_utils.extract_response_content(response)\n",
    "        })\n",
    "        \n",
    "        print(f\"Completed in {elapsed_time:.2f}s, {total_tokens} tokens, ${total_cost:.6f}\\n\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Test with a moderately complex problem\n",
    "test_prompt = \"\"\"\n",
    "A retailer sells two products, Product A and Product B. Product A costs $20 to make and sells for $50. \n",
    "Product B costs $10 to make and sells for $25. The retailer has $2000 available for production costs, \n",
    "and warehouse space for at most 250 units in total.\n",
    "\n",
    "Due to customer demand, they need to produce at least twice as many units of Product B as Product A.\n",
    "\n",
    "What is the optimal production plan to maximize profit?\n",
    "\"\"\"\n",
    "\n",
    "# Run the test\n",
    "budget_test_results = test_reasoning_budgets(test_prompt)\n",
    "\n",
    "# Display a subset of the results (excluding the actual responses to keep the output manageable)\n",
    "display_cols = ['budget', 'elapsed_time', 'total_tokens', 'total_cost', 'efficiency']\n",
    "display(budget_test_results[display_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a3466c-5aca-4a01-afa3-800cee000682",
   "metadata": {},
   "source": [
    "#### Visualizing the Tradeoffs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b606e-da61-42da-a1d4-761fc0b60f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_budget_tradeoffs(df):\n",
    "    \"\"\"\n",
    "    Create visualizations to show the tradeoffs between different budget sizes\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with test results\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Response Time vs. Budget Size\n",
    "    axes[0, 0].plot(df['budget'], df['elapsed_time'], marker='o', linestyle='-', linewidth=2)\n",
    "    axes[0, 0].set_title('Response Time vs. Budget Size', fontsize=14)\n",
    "    axes[0, 0].set_xlabel('Reasoning Budget (tokens)', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Response Time (seconds)', fontsize=12)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Token Usage vs. Budget Size\n",
    "    axes[0, 1].plot(df['budget'], df['total_tokens'], marker='o', linestyle='-', linewidth=2, color='green')\n",
    "    axes[0, 1].set_title('Token Usage vs. Budget Size', fontsize=14)\n",
    "    axes[0, 1].set_xlabel('Reasoning Budget (tokens)', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Total Tokens Used', fontsize=12)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Cost vs. Budget Size\n",
    "    axes[1, 0].plot(df['budget'], df['total_cost'], marker='o', linestyle='-', linewidth=2, color='red')\n",
    "    axes[1, 0].set_title('Cost vs. Budget Size', fontsize=14)\n",
    "    axes[1, 0].set_xlabel('Reasoning Budget (tokens)', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('Total Cost ($)', fontsize=12)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Efficiency vs. Budget Size\n",
    "    axes[1, 1].plot(df['budget'], df['efficiency'], marker='o', linestyle='-', linewidth=2, color='purple')\n",
    "    axes[1, 1].set_title('Efficiency vs. Budget Size', fontsize=14)\n",
    "    axes[1, 1].set_xlabel('Reasoning Budget (tokens)', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Efficiency (Tokens/Second)', fontsize=12)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return the budget size with the highest efficiency\n",
    "    max_efficiency_idx = df['efficiency'].idxmax()\n",
    "    max_efficiency_budget = df.iloc[max_efficiency_idx]['budget']\n",
    "    \n",
    "    print(f\"The most efficient budget size is {max_efficiency_budget} tokens\")\n",
    "    print(f\"This produced {df.iloc[max_efficiency_idx]['total_tokens']} tokens\")\n",
    "    print(f\"In {df.iloc[max_efficiency_idx]['elapsed_time']:.2f} seconds\")\n",
    "    print(f\"At a cost of ${df.iloc[max_efficiency_idx]['total_cost']:.6f}\")\n",
    "\n",
    "# Visualize the results\n",
    "visualize_budget_tradeoffs(budget_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db1c71a-8010-45df-acb1-2329dbd07c08",
   "metadata": {},
   "source": [
    "## Analyzing Response Quality\n",
    "\n",
    "While the quantitative metrics (time, tokens, cost) are important, we also need to consider the **quality** of responses at different budget sizes. Let's examine the responses at the minimum budget (1,024 tokens) compared to the largest budget we tested.\n",
    "\n",
    "This qualitative analysis helps us understand the real-world value we get from allocating larger reasoning budgets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74670d85-6f85-4bb5-84f0-13056b3b9082",
   "metadata": {},
   "source": [
    "#### Comparing Response Quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35bcea-a59a-494c-a403-c8bc32d76503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the response with the smallest budget\n",
    "min_budget = min(budget_test_results['budget'])\n",
    "min_budget_response = budget_test_results[budget_test_results['budget'] == min_budget]['response'].iloc[0]\n",
    "\n",
    "# Display the response with the largest budget\n",
    "max_budget = max(budget_test_results['budget'])\n",
    "max_budget_response = budget_test_results[budget_test_results['budget'] == max_budget]['response'].iloc[0]\n",
    "\n",
    "# Create a comparison display\n",
    "print(f\"Response with {min_budget} tokens budget:\")\n",
    "display(Markdown(min_budget_response))\n",
    "\n",
    "print(f\"\\nResponse with {max_budget} tokens budget:\")\n",
    "display(Markdown(max_budget_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3e3590-9d23-442a-b633-d1fe571523e0",
   "metadata": {},
   "source": [
    "## Implementing Dynamic Budget Allocation\n",
    "\n",
    "Now that we understand the tradeoffs involved, let's implement a dynamic budget allocation strategy that adjusts the reasoning budget based on task complexity.\n",
    "\n",
    "Our approach will:\n",
    "1. Classify the task complexity\n",
    "2. Allocate a reasoning budget based on the complexity\n",
    "3. Apply budget adjustments based on time sensitivity and cost constraints\n",
    "4. Maintain a record of performance for continuous improvement\n",
    "\n",
    "This creates a system that can adapt to different tasks while balancing performance and cost considerations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9392d6-778c-4ac1-80fe-48d1d7272781",
   "metadata": {},
   "source": [
    "## Using Task Complexity to Guide Budget Allocation\n",
    "\n",
    "The first step in our dynamic budget allocation strategy is determining the complexity of the task. Instead of using a fixed budget for all tasks, we'll adjust the reasoning budget based on how complex the task is.\n",
    "\n",
    "### The Task Complexity Classifier\n",
    "\n",
    "We'll implement a `classify_task_complexity` function that:\n",
    "\n",
    "1. Uses a smaller, more efficient model (Claude 3.5 Haiku) to quickly categorize the task\n",
    "2. Classifies tasks into four complexity levels:\n",
    "   - **Simple**: Basic factual questions, straightforward calculations\n",
    "   - **Medium**: Multi-step reasoning, moderate analysis\n",
    "   - **Complex**: Detailed analysis, constraint problems, system design\n",
    "   - **Very Complex**: Advanced mathematical proofs, multi-stage system design\n",
    "\n",
    "This classification serves as the foundation for our budget allocation strategy. Using a smaller model for this classification step is both faster and more cost-effective than using Claude 3.7 Sonnet for the entire process.\n",
    "\n",
    "Think of this as the \"triage\" step in our workflow - similar to how a hospital quickly determines the urgency of each patient to allocate resources appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7dc04b-d775-451f-9b84-9fa4ea8b4f28",
   "metadata": {},
   "source": [
    "#### Task Complexity Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310d6ed5-4e15-4358-b375-79ca0b3a99e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_task_complexity(prompt, model_id='anthropic.claude-3-5-haiku-20241022-v1:0'):\n",
    "    \"\"\"\n",
    "    Use a more efficient model to classify the complexity of a task\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The prompt to classify\n",
    "        model_id (str): Model ID to use for classification\n",
    "        \n",
    "    Returns:\n",
    "        str: Complexity category ('simple', 'medium', 'complex', 'very_complex')\n",
    "    \"\"\"\n",
    "    system_prompt = [\n",
    "        {\"text\": \"\"\"You are a task complexity classifier. Classify the complexity of the given task \n",
    "                   into one of these categories: 'simple', 'medium', 'complex', or 'very_complex'.\n",
    "                   \n",
    "                   Examples:\n",
    "                   - simple: Basic factual questions, straightforward calculations\n",
    "                   - medium: Multi-step reasoning, moderate analysis\n",
    "                   - complex: Detailed analysis, constraint problems, system design\n",
    "                   - very_complex: Advanced mathematical proofs, multi-stage system design\n",
    "                   \n",
    "                   Respond with only the category name, nothing else.\"\"\"}\n",
    "    ]\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": f\"Classify the task complexity: {prompt}\"}]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = bedrock_runtime.converse(\n",
    "            modelId=model_id,\n",
    "            messages=messages,\n",
    "            system=system_prompt,\n",
    "            inferenceConfig={\n",
    "                \"temperature\": 0,\n",
    "                \"maxTokens\": 10  # Only need a short response\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Extract the classification\n",
    "        result = None\n",
    "        if response.get('output', {}).get('message', {}).get('content'):\n",
    "            content_blocks = response['output']['message']['content']\n",
    "            for block in content_blocks:\n",
    "                if 'text' in block:\n",
    "                    result = block['text'].strip().lower()\n",
    "                    break\n",
    "        \n",
    "        # Ensure valid category\n",
    "        valid_categories = ['simple', 'medium', 'complex', 'very_complex']\n",
    "        if result not in valid_categories:\n",
    "            result = 'medium'  # Default if unclear\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying complexity: {e}\")\n",
    "        return \"medium\"  # Default if error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc14d232-167b-404f-b171-a225f37da04f",
   "metadata": {},
   "source": [
    "## The Dynamic Budget Allocator\n",
    "\n",
    "Now that we can classify task complexity, we need a systematic way to determine the appropriate reasoning budget. Our `DynamicBudgetAllocator` class provides this functionality.\n",
    "\n",
    "### Design Philosophy\n",
    "\n",
    "The Dynamic Budget Allocator follows these principles:\n",
    "\n",
    "1. **Complexity-driven**: The primary factor determining budget size is task complexity\n",
    "2. **Context-aware**: Adjusts allocations based on situation (time-sensitive, cost-constrained)\n",
    "3. **Adaptive**: Tracks performance to improve allocation decisions over time\n",
    "4. **Practical**: Balances theoretical ideals with real-world constraints\n",
    "\n",
    "### How It Works\n",
    "\n",
    "The allocator maintains default budget ranges for each complexity level and applies adjustments based on constraints:\n",
    "\n",
    "- For **time-sensitive** situations, it reduces budgets to prioritize faster responses\n",
    "- For **cost-constrained** scenarios, it limits budgets to control expenses\n",
    "- For **simple tasks**, it avoids extended thinking altogether (using standard mode)\n",
    "\n",
    "This approach gives us the flexibility to handle different scenarios while maintaining a consistent allocation logic.\n",
    "\n",
    "Let's implement this class and see how it works in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672fa11-7e84-440e-980a-93e19114fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicBudgetAllocator:\n",
    "    \"\"\"\n",
    "    Allocates reasoning budgets dynamically based on task complexity and constraints\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Default budget ranges by complexity\n",
    "        self.default_budgets = {\n",
    "            'simple': 0,  # No extended thinking for simple tasks\n",
    "            'medium': 2048,\n",
    "            'complex': 4096,\n",
    "            'very_complex': 8192\n",
    "        }\n",
    "        \n",
    "        # Budget adjustments for time sensitivity\n",
    "        self.time_sensitive_adjustments = {\n",
    "            'simple': 0,\n",
    "            'medium': 0,  # No extended thinking when time-sensitive\n",
    "            'complex': -2048,  # Reduce budget for time-sensitive tasks\n",
    "            'very_complex': -4096  # Significant reduction for time-sensitive tasks\n",
    "        }\n",
    "        \n",
    "        # Performance tracking\n",
    "        self.performance_history = {}\n",
    "    \n",
    "    def allocate_budget(self, prompt, time_sensitive=False, cost_constrained=False):\n",
    "        \"\"\"\n",
    "        Allocate an appropriate reasoning budget for a task\n",
    "        \n",
    "        Args:\n",
    "            prompt (str): The user prompt\n",
    "            time_sensitive (bool): Whether the task is time-sensitive\n",
    "            cost_constrained (bool): Whether to prioritize cost saving\n",
    "            \n",
    "        Returns:\n",
    "            dict: Allocation decision including reasoning budget and strategy details\n",
    "        \"\"\"\n",
    "        # Step 1: Classify task complexity\n",
    "        complexity = classify_task_complexity(prompt)\n",
    "        \n",
    "        # Step 2: Get base budget for this complexity\n",
    "        base_budget = self.default_budgets.get(complexity, 2048)\n",
    "        \n",
    "        # Step 3: Apply adjustments\n",
    "        final_budget = base_budget\n",
    "        \n",
    "        # Apply time sensitivity adjustment\n",
    "        if time_sensitive and complexity in self.time_sensitive_adjustments:\n",
    "            final_budget += self.time_sensitive_adjustments[complexity]\n",
    "        \n",
    "        # Apply cost constraint adjustment (reduce by 50% if cost constrained)\n",
    "        if cost_constrained and final_budget > 0:\n",
    "            final_budget = max(1024, final_budget // 2)  # Minimum 1024 if using extended thinking\n",
    "        \n",
    "        # Step 4: Determine whether to use extended thinking\n",
    "        use_extended_thinking = final_budget >= 1024\n",
    "        \n",
    "        # If not using extended thinking, set budget to 0\n",
    "        if not use_extended_thinking:\n",
    "            final_budget = 0\n",
    "        \n",
    "        # Step 5: Create allocation decision\n",
    "        allocation = {\n",
    "            'complexity': complexity,\n",
    "            'use_extended_thinking': use_extended_thinking,\n",
    "            'reasoning_budget': final_budget,\n",
    "            'time_sensitive': time_sensitive,\n",
    "            'cost_constrained': cost_constrained\n",
    "        }\n",
    "        \n",
    "        return allocation\n",
    "    \n",
    "    def update_performance(self, allocation, elapsed_time, token_count, cost):\n",
    "        \"\"\"\n",
    "        Update performance history for continuous learning\n",
    "        \n",
    "        Args:\n",
    "            allocation (dict): The allocation decision\n",
    "            elapsed_time (float): Time taken for response\n",
    "            token_count (int): Total tokens used\n",
    "            cost (float): Total cost\n",
    "        \"\"\"\n",
    "        complexity = allocation['complexity']\n",
    "        budget = allocation['reasoning_budget']\n",
    "        \n",
    "        if complexity not in self.performance_history:\n",
    "            self.performance_history[complexity] = []\n",
    "        \n",
    "        self.performance_history[complexity].append({\n",
    "            'budget': budget,\n",
    "            'elapsed_time': elapsed_time,\n",
    "            'token_count': token_count,\n",
    "            'cost': cost,\n",
    "            'timestamp': time.time()\n",
    "        })\n",
    "\n",
    "# Create an instance of our allocator\n",
    "budget_allocator = DynamicBudgetAllocator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713bafdc-dcca-4d86-aabb-8017adda2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dynamic_allocation(prompts, allocator):\n",
    "    \"\"\"\n",
    "    Test our dynamic budget allocator on a set of prompts\n",
    "    \n",
    "    Args:\n",
    "        prompts (dict): Dictionary of prompt labels to prompt text\n",
    "        allocator (DynamicBudgetAllocator): The budget allocator\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Results of the test\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for label, prompt in prompts.items():\n",
    "        print(f\"\\nTesting prompt: {label}\")\n",
    "        print(f\"Prompt: {prompt[:100]}...\" if len(prompt) > 100 else f\"Prompt: {prompt}\")\n",
    "        \n",
    "        # Get allocation for standard mode (not time-sensitive)\n",
    "        standard_allocation = allocator.allocate_budget(prompt, time_sensitive=False)\n",
    "        print(f\"Standard mode allocation: {standard_allocation}\")\n",
    "        \n",
    "        # Get allocation for time-sensitive mode\n",
    "        time_sensitive_allocation = allocator.allocate_budget(prompt, time_sensitive=True)\n",
    "        print(f\"Time-sensitive allocation: {time_sensitive_allocation}\")\n",
    "        \n",
    "        # Execute with the standard allocation\n",
    "        print(f\"\\nExecuting with standard allocation...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = claude_utils.invoke_claude(\n",
    "            bedrock_runtime,\n",
    "            prompt,\n",
    "            CLAUDE_37_SONNET_MODEL_ID,\n",
    "            enable_reasoning=standard_allocation['use_extended_thinking'],\n",
    "            reasoning_budget=standard_allocation['reasoning_budget'],\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # Calculate metrics\n",
    "        input_tokens = response.get('usage', {}).get('inputTokens', 0)\n",
    "        output_tokens = response.get('usage', {}).get('outputTokens', 0)\n",
    "        total_tokens = response.get('usage', {}).get('totalTokens', 0)\n",
    "        total_cost = (input_tokens * 0.000003) + (output_tokens * 0.000015)\n",
    "        \n",
    "        # Update allocator's performance history\n",
    "        allocator.update_performance(\n",
    "            standard_allocation,\n",
    "            elapsed_time,\n",
    "            total_tokens,\n",
    "            total_cost\n",
    "        )\n",
    "        \n",
    "        # Store result\n",
    "        results.append({\n",
    "            'Prompt': label,\n",
    "            'Complexity': standard_allocation['complexity'],\n",
    "            'Use_Extended_Thinking': standard_allocation['use_extended_thinking'],\n",
    "            'Reasoning_Budget': standard_allocation['reasoning_budget'],\n",
    "            'Time_Sensitive_Budget': time_sensitive_allocation['reasoning_budget'],\n",
    "            'Elapsed_Time': elapsed_time,\n",
    "            'Total_Tokens': total_tokens,\n",
    "            'Total_Cost': total_cost\n",
    "        })\n",
    "        \n",
    "        print(f\"Completed in {elapsed_time:.2f}s, {total_tokens} tokens, ${total_cost:.6f}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Test prompts of varying complexity\n",
    "test_prompts = {\n",
    "    \"Simple_Fact\": \"What is the capital of France?\",\n",
    "    \n",
    "    \"Medium_Math\": \"If a rectangle has a perimeter of 30 units and a width of 5 units, what is its area?\",\n",
    "    \n",
    "    \"Complex_Analysis\": \"\"\"\n",
    "    Analyze the advantages and disadvantages of implementing a universal basic income \n",
    "    in a developed economy. Consider economic, social, and political perspectives.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Very_Complex_Design\": \"\"\"\n",
    "    Design a system for urban traffic management that optimizes traffic flow, reduces congestion,\n",
    "    minimizes emissions, and adapts to changing conditions. Include sensing, data processing,\n",
    "    decision-making components, and how they would interact.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Run the test\n",
    "allocation_test_results = test_dynamic_allocation(test_prompts, budget_allocator)\n",
    "\n",
    "# Display the results\n",
    "display(allocation_test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4914757e-c498-4899-b648-ad923aab9de5",
   "metadata": {},
   "source": [
    "## Practical Strategies for Different Scenarios\n",
    "\n",
    "Based on our experiments and analysis, here are some practical strategies for different scenarios:\n",
    "\n",
    "### Time-Sensitive Applications\n",
    "For applications where response time is critical (e.g., customer service chatbots, real-time assistants):\n",
    "\n",
    "- Use standard mode (no extended thinking) for simple and medium complexity tasks\n",
    "- Use minimal reasoning budgets (1,024-2,048 tokens) for complex tasks\n",
    "- Consider a two-stage approach: quick response first, then deeper analysis if requested\n",
    "\n",
    "### Depth-Critical Applications\n",
    "For applications where reasoning quality and depth is the priority (e.g., research assistance, complex analysis):\n",
    "\n",
    "- Use extended thinking for all but the simplest tasks\n",
    "- Allocate generous reasoning budgets (4,096+ tokens) for complex and very complex tasks\n",
    "- Consider progressive enhancement: start with medium budgets, increase if needed\n",
    "\n",
    "### Cost-Sensitive Applications\n",
    "For applications with tight budget constraints:\n",
    "\n",
    "- Only use extended thinking for complex and very complex tasks\n",
    "- Limit reasoning budgets to the most efficient sizes identified through testing\n",
    "- Consider caching common responses to avoid repeated reasoning costs\n",
    "\n",
    "### Balanced Approach\n",
    "For general-purpose applications balancing all factors:\n",
    "\n",
    "- Use our dynamic allocation system with complexity-based budgeting\n",
    "- Track performance metrics over time to identify optimal budgets for different task types\n",
    "- Adjust allocations based on user feedback and business requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae15fe6c-6562-4cc0-81b1-b8bd4095077f",
   "metadata": {},
   "source": [
    "#### Visualizing the Dynamic Allocation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7afc7cf-2503-408f-9e7d-69b813aff9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_allocation_strategy():\n",
    "    \"\"\"\n",
    "    Create a visualization of our dynamic allocation strategy\n",
    "    \"\"\"\n",
    "    # Define complexity levels and scenarios\n",
    "    complexities = ['Simple', 'Medium', 'Complex', 'Very Complex']\n",
    "    scenarios = ['Standard', 'Time-Sensitive', 'Cost-Constrained']\n",
    "    \n",
    "    # Get budgets for each combination\n",
    "    budgets = {}\n",
    "    for scenario in scenarios:\n",
    "        budgets[scenario] = []\n",
    "        time_sensitive = scenario == 'Time-Sensitive'\n",
    "        cost_constrained = scenario == 'Cost-Constrained'\n",
    "        \n",
    "        for complexity in complexities:\n",
    "            # Create a sample prompt for each complexity\n",
    "            if complexity == 'Simple':\n",
    "                prompt = \"What is the capital of France?\"\n",
    "            elif complexity == 'Medium':\n",
    "                prompt = \"Explain the greenhouse effect in simple terms.\"\n",
    "            elif complexity == 'Complex':\n",
    "                prompt = \"Analyze the impacts of artificial intelligence on employment in the next decade.\"\n",
    "            else:  # Very Complex\n",
    "                prompt = \"Design a system for managing autonomous vehicle traffic in a smart city.\"\n",
    "            \n",
    "            # Get allocation\n",
    "            allocation = budget_allocator.allocate_budget(\n",
    "                prompt, \n",
    "                time_sensitive=time_sensitive,\n",
    "                cost_constrained=cost_constrained\n",
    "            )\n",
    "            \n",
    "            budgets[scenario].append(allocation['reasoning_budget'])\n",
    "    \n",
    "    # Create the visualization\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Set up the bar positions\n",
    "    bar_width = 0.25\n",
    "    r1 = np.arange(len(complexities))\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "    r3 = [x + bar_width for x in r2]\n",
    "    \n",
    "    # Create the bars\n",
    "    ax.bar(r1, budgets['Standard'], width=bar_width, label='Standard', color='blue', alpha=0.7)\n",
    "    ax.bar(r2, budgets['Time-Sensitive'], width=bar_width, label='Time-Sensitive', color='red', alpha=0.7)\n",
    "    ax.bar(r3, budgets['Cost-Constrained'], width=bar_width, label='Cost-Constrained', color='green', alpha=0.7)\n",
    "    \n",
    "    # Add labels and legend\n",
    "    ax.set_xlabel('Task Complexity', fontsize=14)\n",
    "    ax.set_ylabel('Reasoning Budget (tokens)', fontsize=14)\n",
    "    ax.set_title('Dynamic Budget Allocation Strategy', fontsize=16)\n",
    "    ax.set_xticks([r + bar_width for r in range(len(complexities))])\n",
    "    ax.set_xticklabels(complexities)\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add a horizontal line at 1024 tokens (minimum budget)\n",
    "    ax.axhline(y=1024, color='gray', linestyle='--', alpha=0.7)\n",
    "    ax.text(3.5, 1100, 'Minimum Budget (1,024 tokens)', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize our allocation strategy\n",
    "visualize_allocation_strategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d642e94-4afe-42cc-83c4-0da0e52a87aa",
   "metadata": {},
   "source": [
    "## Case Study: Budget Optimization for a Complex Task\n",
    "\n",
    "To apply what we've learned, let's walk through a case study of optimizing the reasoning budget for a complex task - developing a strategy for climate change mitigation.\n",
    "\n",
    "This case study demonstrates how to:\n",
    "1. Start with an appropriate budget based on task complexity\n",
    "2. Evaluate the results against your specific requirements\n",
    "3. Adjust as needed to find the optimal balance\n",
    "\n",
    "The ideal budget will vary based on your specific priorities (quality vs. speed vs. cost), but this process provides a systematic approach to finding the right balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61656d93-491c-40b2-a95f-8b0291c9dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_case_study():\n",
    "    \"\"\"\n",
    "    Run a case study on budget optimization for a complex task\n",
    "    \"\"\"\n",
    "    # Define our complex task\n",
    "    case_study_prompt = \"\"\"\n",
    "    Develop a comprehensive strategy for a mid-sized city (population 500,000) to reduce its carbon emissions\n",
    "    by 50% by 2035. Consider transportation, buildings, energy generation, industry, and waste management.\n",
    "    Include specific policy recommendations, technological solutions, financing mechanisms, and implementation timeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Case Study: Carbon Emission Reduction Strategy\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Prompt: {case_study_prompt}\")\n",
    "    \n",
    "    # Step 1: Classify the task\n",
    "    complexity = classify_task_complexity(case_study_prompt)\n",
    "    print(f\"\\nTask classified as: {complexity}\")\n",
    "    \n",
    "    # Step 2: Get the recommended budget from our allocator\n",
    "    allocation = budget_allocator.allocate_budget(case_study_prompt)\n",
    "    recommended_budget = allocation['reasoning_budget']\n",
    "    print(f\"Recommended budget: {recommended_budget} tokens\")\n",
    "    \n",
    "    # Step 3: Test a range of budgets around the recommendation\n",
    "    test_budgets = [\n",
    "        max(1024, recommended_budget // 2),  # Half (or minimum)\n",
    "        recommended_budget,                   # Recommended\n",
    "        min(16384, recommended_budget * 2)    # Double (or maximum)\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nTesting budgets: {test_budgets}\")\n",
    "    \n",
    "    results = []\n",
    "    response_texts = {}\n",
    "    \n",
    "    for budget in test_budgets:\n",
    "        print(f\"\\nTesting budget: {budget} tokens\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        response = claude_utils.invoke_claude(\n",
    "            bedrock_runtime,\n",
    "            case_study_prompt,\n",
    "            CLAUDE_37_SONNET_MODEL_ID,\n",
    "            enable_reasoning=True,\n",
    "            reasoning_budget=budget,\n",
    "            max_tokens=1500\n",
    "        )\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # Extract metrics\n",
    "        input_tokens = response.get('usage', {}).get('inputTokens', 0)\n",
    "        output_tokens = response.get('usage', {}).get('outputTokens', 0)\n",
    "        total_tokens = response.get('usage', {}).get('totalTokens', 0)\n",
    "        total_cost = (input_tokens * 0.000003) + (output_tokens * 0.000015)\n",
    "        \n",
    "        # Store response text\n",
    "        response_text = claude_utils.extract_response_content(response)\n",
    "        response_texts[budget] = response_text\n",
    "        \n",
    "        # Calculate tokens per second\n",
    "        tokens_per_second = total_tokens / elapsed_time if elapsed_time > 0 else 0\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Budget': budget,\n",
    "            'Time (s)': elapsed_time,\n",
    "            'Tokens': total_tokens,\n",
    "            'Cost ($)': total_cost,\n",
    "            'Tokens/Second': tokens_per_second\n",
    "        })\n",
    "        \n",
    "        print(f\"Completed in {elapsed_time:.2f}s, {total_tokens} tokens, ${total_cost:.6f}\")\n",
    "    \n",
    "    # Display results table\n",
    "    results_df = pd.DataFrame(results)\n",
    "    display(results_df)\n",
    "    \n",
    "    # Plot the results\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Time plot\n",
    "    ax[0].plot([r['Budget'] for r in results], [r['Time (s)'] for r in results], 'o-', linewidth=2)\n",
    "    ax[0].set_title('Time vs. Budget')\n",
    "    ax[0].set_xlabel('Budget (tokens)')\n",
    "    ax[0].set_ylabel('Time (seconds)')\n",
    "    ax[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Cost plot\n",
    "    ax[1].plot([r['Budget'] for r in results], [r['Cost ($)'] for r in results], 'o-', linewidth=2, color='red')\n",
    "    ax[1].set_title('Cost vs. Budget')\n",
    "    ax[1].set_xlabel('Budget (tokens)')\n",
    "    ax[1].set_ylabel('Cost ($)')\n",
    "    ax[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Efficiency plot\n",
    "    ax[2].plot([r['Budget'] for r in results], [r['Tokens/Second'] for r in results], 'o-', linewidth=2, color='green')\n",
    "    ax[2].set_title('Efficiency vs. Budget')\n",
    "    ax[2].set_xlabel('Budget (tokens)')\n",
    "    ax[2].set_ylabel('Tokens per Second')\n",
    "    ax[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show response previews\n",
    "    for budget, text in response_texts.items():\n",
    "        print(f\"\\nResponse preview ({budget} tokens budget):\")\n",
    "        print(\"-\" * 80)\n",
    "        # Display first 300 characters\n",
    "        preview = text[:300] + \"...\" if len(text) > 300 else text\n",
    "        print(preview)\n",
    "    \n",
    "    # Final recommendation\n",
    "    most_efficient_idx = np.argmax([r['Tokens/Second'] for r in results])\n",
    "    most_efficient_budget = results[most_efficient_idx]['Budget']\n",
    "    \n",
    "    fastest_idx = np.argmin([r['Time (s)'] for r in results])\n",
    "    fastest_budget = results[fastest_idx]['Budget']\n",
    "    \n",
    "    print(\"\\nRecommendations:\")\n",
    "    print(f\"- For maximum efficiency: {most_efficient_budget} tokens budget\")\n",
    "    print(f\"- For fastest response: {fastest_budget} tokens budget\")\n",
    "    print(\"- For optimal quality/cost balance: Review the response content and choose based on your requirements\")\n",
    "\n",
    "# Run the case study\n",
    "run_case_study()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa865f3-4b54-413d-a2b4-73c55f2386cb",
   "metadata": {},
   "source": [
    "## Conclusion and Best Practices\n",
    "\n",
    "In this notebook, we've explored how to optimize Claude 3.7 Sonnet's reasoning budget allocation to balance quality, cost, and performance. Here are the key takeaways:\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "1. **Budget Size Tradeoffs**: \n",
    "   - Larger budgets generally lead to more thorough reasoning\n",
    "   - But also increase response time and cost\n",
    "   - There's a point of diminishing returns for each task type\n",
    "\n",
    "2. **Dynamic Allocation Strategy**:\n",
    "   - Task complexity is the primary factor in budget allocation\n",
    "   - Time sensitivity and cost constraints are important secondary factors\n",
    "   - Different scenarios require different allocation strategies\n",
    "\n",
    "3. **Finding the Optimal Budget**:\n",
    "   - Start with a complexity-based recommendation\n",
    "   - Test a range of budgets to find the balance of quality, time, and cost\n",
    "   - Track performance metrics to refine your approach over time\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **For Production Systems**:\n",
    "   - Implement task complexity classification as a first step\n",
    "   - Use dynamic budget allocation based on use case requirements\n",
    "   - Monitor and analyze performance to continuously optimize\n",
    "\n",
    "2. **For Cost Optimization**:\n",
    "   - Only use extended thinking when the complexity justifies it\n",
    "   - Find the \"efficiency sweet spot\" for each task type\n",
    "   - Consider caching common responses\n",
    "\n",
    "3. **For Quality Optimization**:\n",
    "   - Allocate larger budgets for complex tasks where quality is critical\n",
    "   - Implement a feedback loop to identify when larger budgets are needed\n",
    "   - Consider adjusting the prompt to focus the reasoning process\n",
    "\n",
    "By implementing these practices, you can make the most of Claude 3.7 Sonnet's extended thinking capabilities while optimizing for your specific requirements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
